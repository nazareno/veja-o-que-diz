---
title: "Termos nas lives"
output:
  html_document:
      css: styles.css
      df_print: paged
      
theme: sandstone
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  warning = FALSE,
  message = FALSE,
  fig.cap = '',
  fig.align = 'center',
  fig.width = 10,
  fig.height = 8
)
```

```{r}
library(tidyverse)
library(ggwordcloud)
library(tidytext)
library(stopwords)
library(DT)

theme_set(theme_minimal())

PALAVRAS_A_IGNORAR = c(stopwords("pt"), "aqui", "é", "vai", "ser", "pra", "muito", "muita", "boa", "horas", "outra coisa", "coisa", "então", "para")
```

```{r}
falas_raw = read_csv2(here::here("data/bolsonaro-lives.txt"), 
                      col_names = c("video", "closed_caption"), 
                      col_types = "cc")
```

Usamos aqui a transcrição que o youtube gera para closed captions nas lives dos seguintes vídeos: 

```{r}
falas_raw %>% 
  select(video) 
```


```{r}
contagens_uni = falas_raw %>% 
  unnest_tokens(termo, 
                closed_caption, 
                token = "words", 
                stopwords = PALAVRAS_A_IGNORAR,
                collapse = F) %>%
  count(video, termo) %>%
  filter(str_length(termo) > 3) %>% 
  count(termo, sort = T) %>% 
  top_n(100, n)

contagens_uni %>% 
  datatable(class = 'cell-border stripe',
            filter = 'top',
            rownames = FALSE, 
            options = list(pageLength = 5,
                           dom = 'ftp'),
            colnames = c("Termo", "Número de lives"))
```

```{r}
contagens_uni %>% 
  ggplot(aes(label = termo, size = n)) +
    geom_text_wordcloud_area(show.legend = T, area_corr_power = 1, color = "tomato") +
    scale_x_discrete(breaks = NULL) +
    scale_size_area(guide = "none") +
    labs(title = "Palavras mais comuns",
         x = "")
```



```{r}
contagens_bi = falas_raw %>% 
  unnest_tokens(termo, 
                closed_caption, 
                token = "ngrams", 
                n = 2, 
                stopwords = PALAVRAS_A_IGNORAR,
                collapse = F) %>%
  count(video, termo) %>%
  filter(str_length(termo) > 3) %>% 
  count(termo, sort = T) %>% 
  filter(n > 3) 
  
contagens_bi %>% 
    datatable(class = 'cell-border stripe',
            filter = 'top',
            rownames = FALSE, 
            options = list(pageLength = 5,
                           dom = 'ftp'),
            colnames = c("Termo", "Número de lives"))
```

```{r}
contagens_bi %>% 
  top_n(30, n) %>% 
  ggplot(aes(label = termo, size = n)) +
  geom_text_wordcloud_area(show.legend = T, area_corr_power = 1, color = "tomato") +
  scale_x_discrete(breaks = NULL) +
  scale_size_area(guide = "none") +
  labs(title = "Pares de palavras mais comuns",
       x = "") 
```

```{r}
contagens_bi %>% 
  top_n(30, n) %>% 
  ggplot(aes(x = reorder(termo, n), y = n)) + 
  geom_col(fill = "salmon") + 
  coord_flip() + 
  labs(x = "", y = "lives em que foi mencionado", title = "Par de palavras")
```


```{r}
contagens_tri = falas_raw %>% 
  unnest_tokens(termo, 
                closed_caption, 
                token = "ngrams", 
                n = 3, 
                stopwords = PALAVRAS_A_IGNORAR,
                collapse = F) %>%
  count(video, termo) %>%
  filter(str_length(termo) > 3) %>% 
  count(termo, sort = T) %>% 
  filter(n > 2) 

contagens_tri %>% 
    datatable(class = 'cell-border stripe',
            filter = 'top',
            rownames = FALSE, 
            options = list(pageLength = 5,
                           dom = 'ftp'),
            colnames = c("Termo", "Número de lives"))
```

```{r}
contagens_tri %>% 
  top_n(30, n) %>% 
  ggplot(aes(x = reorder(termo, n), y = n)) + 
  geom_col(fill = "salmon") + 
  coord_flip() + 
  labs(x = "", y = "lives em que foi mencionado", title = "Par de palavras")

```

